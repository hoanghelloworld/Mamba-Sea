{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "339a424a",
   "metadata": {},
   "source": [
    "# Mamba-Sea Training Notebook for Custom Segmentation Dataset\n",
    "\n",
    "This notebook demonstrates how to train the Mamba-Sea model on your custom dataset with the following structure:\n",
    "- train/images (.jpg)\n",
    "- train/masks (.png with 0-255 values)\n",
    "- val/images (.jpg) \n",
    "- val/masks (.png with 0-255 values)\n",
    "- test/images (.jpg - no masks)\n",
    "\n",
    "After training, the model will predict on test data and save results to a new folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bab2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c27dee",
   "metadata": {},
   "source": [
    "## Configuration and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fa2617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'data_root': './data',  # Path to your data folder\n",
    "    'image_size': 512,\n",
    "    'batch_size': 8,\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_workers': 4,\n",
    "    'save_path': './checkpoints',\n",
    "    'prediction_path': './predictions',\n",
    "    'model_type': 'VMUNet',  # or 'VMUnet_enhance'\n",
    "}\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(CONFIG['save_path'], exist_ok=True)\n",
    "os.makedirs(CONFIG['prediction_path'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbae0a6a",
   "metadata": {},
   "source": [
    "## Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45055ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSegmentationDataset(Dataset):\n",
    "    def __init__(self, data_root, split='train', image_size=512, augment=True):\n",
    "        self.data_root = Path(data_root)\n",
    "        self.split = split\n",
    "        self.image_size = image_size\n",
    "        self.augment = augment and split == 'train'\n",
    "        \n",
    "        # Get image paths\n",
    "        if split == 'test':\n",
    "            self.image_dir = self.data_root / 'test' / 'images'\n",
    "            self.mask_dir = None\n",
    "            self.image_paths = list(self.image_dir.glob('*.jpg'))\n",
    "        else:\n",
    "            self.image_dir = self.data_root / split / 'images'\n",
    "            self.mask_dir = self.data_root / split / 'masks'\n",
    "            self.image_paths = list(self.image_dir.glob('*.jpg'))\n",
    "        \n",
    "        print(f\"{split} dataset: {len(self.image_paths)} images\")\n",
    "        \n",
    "        # Define transforms\n",
    "        if self.augment:\n",
    "            self.transform = A.Compose([\n",
    "                A.Resize(image_size, image_size),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                A.RandomRotate90(p=0.5),\n",
    "                A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "                A.RandomBrightnessContrast(p=0.3),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = A.Compose([\n",
    "                A.Resize(image_size, image_size),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "            \n",
    "        self.mask_transform = A.Compose([\n",
    "            A.Resize(image_size, image_size, interpolation=cv2.INTER_NEAREST),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(str(image_path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.split == 'test':\n",
    "            # For test data, only return image and filename\n",
    "            transformed = self.transform(image=image)\n",
    "            return transformed['image'], image_path.name\n",
    "        \n",
    "        # Load mask\n",
    "        mask_name = image_path.stem + '.png'\n",
    "        mask_path = self.mask_dir / mask_name\n",
    "        \n",
    "        if not mask_path.exists():\n",
    "            raise FileNotFoundError(f\"Mask not found: {mask_path}\")\n",
    "            \n",
    "        mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Convert mask to binary (0 or 1)\n",
    "        mask = (mask > 127).astype(np.uint8)\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.augment:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image, mask = transformed['image'], transformed['mask']\n",
    "        else:\n",
    "            image_transformed = self.transform(image=image)\n",
    "            mask_transformed = self.mask_transform(image=mask)\n",
    "            image, mask = image_transformed['image'], mask_transformed['image']\n",
    "        \n",
    "        # Ensure mask is long tensor for CrossEntropyLoss\n",
    "        mask = mask.long().squeeze(0) if mask.dim() > 2 else mask.long()\n",
    "        \n",
    "        return image, mask, image_path.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3171401",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc1c6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model factory\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "from model import factory\n",
    "\n",
    "# Initialize model\n",
    "model = factory(CONFIG['model_type'], 3, 2)  # 3 input channels, 2 classes (background + foreground)\n",
    "\n",
    "# Load pretrained weights if available\n",
    "try:\n",
    "    model.load_from()\n",
    "    print(\"Loaded pretrained weights successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load pretrained weights: {e}\")\n",
    "    print(\"Training from scratch\")\n",
    "\n",
    "model = model.to(device)\n",
    "print(f\"Model loaded: {CONFIG['model_type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eb7264",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c704801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = CustomSegmentationDataset(CONFIG['data_root'], 'train', CONFIG['image_size'], augment=True)\n",
    "val_dataset = CustomSegmentationDataset(CONFIG['data_root'], 'val', CONFIG['image_size'], augment=False)\n",
    "test_dataset = CustomSegmentationDataset(CONFIG['data_root'], 'test', CONFIG['image_size'], augment=False)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, \n",
    "                         num_workers=CONFIG['num_workers'], pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, \n",
    "                       num_workers=CONFIG['num_workers'], pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, \n",
    "                        num_workers=CONFIG['num_workers'], pin_memory=True)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d9d9f7",
   "metadata": {},
   "source": [
    "## Loss Functions and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660ec0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        pred = torch.softmax(pred, dim=1)\n",
    "        target_one_hot = torch.zeros_like(pred)\n",
    "        target_one_hot.scatter_(1, target.unsqueeze(1), 1)\n",
    "        \n",
    "        intersection = (pred * target_one_hot).sum(dim=(2, 3))\n",
    "        union = pred.sum(dim=(2, 3)) + target_one_hot.sum(dim=(2, 3))\n",
    "        \n",
    "        dice = (2. * intersection + self.smooth) / (union + self.smooth)\n",
    "        return 1 - dice.mean()\n",
    "\n",
    "# Combined loss\n",
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "criterion_dice = DiceLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG['num_epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d0ecab",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f54ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dice_score(pred, target, smooth=1):\n",
    "    pred = torch.softmax(pred, dim=1)\n",
    "    pred = torch.argmax(pred, dim=1)\n",
    "    \n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum()\n",
    "    \n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return dice.item()\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, criterion_ce, criterion_dice, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_dice = 0\n",
    "    num_batches = len(train_loader)\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc='Training')\n",
    "    for batch_idx, (images, masks, _) in enumerate(pbar):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss_ce = criterion_ce(outputs, masks)\n",
    "        loss_dice = criterion_dice(outputs, masks)\n",
    "        loss = loss_ce + loss_dice\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        dice_score = calculate_dice_score(outputs, masks)\n",
    "        total_dice += dice_score\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Dice': f'{dice_score:.4f}',\n",
    "            'Avg Loss': f'{total_loss/(batch_idx+1):.4f}',\n",
    "            'Avg Dice': f'{total_dice/(batch_idx+1):.4f}'\n",
    "        })\n",
    "    \n",
    "    return total_loss / num_batches, total_dice / num_batches\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion_ce, criterion_dice, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_dice = 0\n",
    "    num_batches = len(val_loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc='Validation')\n",
    "        for batch_idx, (images, masks, _) in enumerate(pbar):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss_ce = criterion_ce(outputs, masks)\n",
    "            loss_dice = criterion_dice(outputs, masks)\n",
    "            loss = loss_ce + loss_dice\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            dice_score = calculate_dice_score(outputs, masks)\n",
    "            total_dice += dice_score\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Dice': f'{dice_score:.4f}',\n",
    "                'Avg Loss': f'{total_loss/(batch_idx+1):.4f}',\n",
    "                'Avg Dice': f'{total_dice/(batch_idx+1):.4f}'\n",
    "            })\n",
    "    \n",
    "    return total_loss / num_batches, total_dice / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5418bf",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604b46b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "best_dice = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_dices = []\n",
    "val_dices = []\n",
    "\n",
    "for epoch in range(CONFIG['num_epochs']):\n",
    "    print(f\"\\nEpoch {epoch+1}/{CONFIG['num_epochs']}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_dice = train_epoch(model, train_loader, optimizer, criterion_ce, criterion_dice, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_dice = validate_epoch(model, val_loader, criterion_ce, criterion_dice, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Store metrics\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_dices.append(train_dice)\n",
    "    val_dices.append(val_dice)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Dice: {val_dice:.4f}\")\n",
    "    print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_dice > best_dice:\n",
    "        best_dice = val_dice\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_dice': best_dice,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'train_dice': train_dice,\n",
    "            'val_dice': val_dice\n",
    "        }, os.path.join(CONFIG['save_path'], 'best_model.pth'))\n",
    "        print(f\"New best model saved with Dice: {best_dice:.4f}\")\n",
    "    \n",
    "    # Save latest model\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_dice': best_dice,\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'train_dice': train_dice,\n",
    "        'val_dice': val_dice\n",
    "    }, os.path.join(CONFIG['save_path'], 'latest_model.pth'))\n",
    "\n",
    "print(f\"\\nTraining completed! Best Dice score: {best_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b82014",
   "metadata": {},
   "source": [
    "## Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15400548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(train_losses, label='Train Loss')\n",
    "ax1.plot(val_losses, label='Val Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Dice plot\n",
    "ax2.plot(train_dices, label='Train Dice')\n",
    "ax2.plot(val_dices, label='Val Dice')\n",
    "ax2.set_title('Training and Validation Dice Score')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Dice Score')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(CONFIG['save_path'], 'training_history.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85d80c8",
   "metadata": {},
   "source": [
    "## Load Best Model for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee41a4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(os.path.join(CONFIG['save_path'], 'best_model.pth'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model with Dice score: {checkpoint['best_dice']:.4f}\")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a6fe19",
   "metadata": {},
   "source": [
    "## Prediction on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be570c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_save(model, test_loader, save_path, device):\n",
    "    \"\"\"Predict on test data and save results\"\"\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(test_loader, desc='Predicting')\n",
    "        for images, filenames in pbar:\n",
    "            images = images.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            predictions = torch.softmax(outputs, dim=1)\n",
    "            predictions = torch.argmax(predictions, dim=1)\n",
    "            \n",
    "            # Process each image in the batch\n",
    "            for i, filename in enumerate(filenames):\n",
    "                pred_mask = predictions[i].cpu().numpy()\n",
    "                \n",
    "                # Convert to 0-255 range\n",
    "                pred_mask = (pred_mask * 255).astype(np.uint8)\n",
    "                \n",
    "                # Save prediction\n",
    "                save_filename = os.path.splitext(filename)[0] + '_pred.png'\n",
    "                save_filepath = os.path.join(save_path, save_filename)\n",
    "                \n",
    "                Image.fromarray(pred_mask).save(save_filepath)\n",
    "                \n",
    "            pbar.set_postfix({'Processed': len(filenames)})\n",
    "    \n",
    "    print(f\"Predictions saved to: {save_path}\")\n",
    "\n",
    "# Run prediction\n",
    "predict_and_save(model, test_loader, CONFIG['prediction_path'], device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a60396",
   "metadata": {},
   "source": [
    "## Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7d65d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(test_dataset, model, device, num_samples=6):\n",
    "    \"\"\"Visualize some test predictions\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(20, 8))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "    \n",
    "    indices = np.random.choice(len(test_dataset), num_samples, replace=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, idx in enumerate(indices):\n",
    "            image, filename = test_dataset[idx]\n",
    "            \n",
    "            # Original image for display (denormalize)\n",
    "            orig_image = image.clone()\n",
    "            orig_image = orig_image * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "            orig_image = orig_image + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "            orig_image = torch.clamp(orig_image, 0, 1)\n",
    "            orig_image = orig_image.permute(1, 2, 0).numpy()\n",
    "            \n",
    "            # Prediction\n",
    "            image_batch = image.unsqueeze(0).to(device)\n",
    "            output = model(image_batch)\n",
    "            pred = torch.softmax(output, dim=1)\n",
    "            pred = torch.argmax(pred, dim=1).squeeze().cpu().numpy()\n",
    "            \n",
    "            # Display\n",
    "            axes[0, i].imshow(orig_image)\n",
    "            axes[0, i].set_title(f'Original: {filename}')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            axes[1, i].imshow(pred, cmap='gray')\n",
    "            axes[1, i].set_title('Prediction')\n",
    "            axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(CONFIG['save_path'], 'prediction_samples.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize some predictions\n",
    "visualize_predictions(test_dataset, model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fd6fba",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Training completed successfully! Here's what was accomplished:\n",
    "\n",
    "1. **Custom Dataset**: Created a dataset class that handles your specific data structure\n",
    "2. **Model Training**: Trained the Mamba-Sea model with combined CE + Dice loss\n",
    "3. **Evaluation**: Monitored training with Dice score metrics\n",
    "4. **Prediction**: Generated predictions on test data and saved them to a new folder\n",
    "5. **Visualization**: Created plots showing training progress and sample predictions\n",
    "\n",
    "### Output Files:\n",
    "- `./checkpoints/best_model.pth` - Best model weights\n",
    "- `./checkpoints/latest_model.pth` - Latest model weights  \n",
    "- `./checkpoints/training_history.png` - Training curves\n",
    "- `./checkpoints/prediction_samples.png` - Sample predictions\n",
    "- `./predictions/` - Folder containing all test predictions\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with different model configurations\n",
    "- Try data augmentation techniques\n",
    "- Tune hyperparameters for better performance\n",
    "- Evaluate on validation set with additional metrics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
